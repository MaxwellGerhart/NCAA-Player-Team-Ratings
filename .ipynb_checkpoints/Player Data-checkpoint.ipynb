{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23605612-fd4f-4f09-833f-3387b4d66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7b27120-db55-4a5f-8036-2c9c9d854257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the page you want to scrape\n",
    "def get_game_ids(day, division):\n",
    "    \n",
    "    url = f\"https://www.ncaa.com/scoreboard/soccer-men/{division}/2024/{day}\"\n",
    "    print(url)\n",
    "\n",
    "    # Send a request to fetch the HTML content of the page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all 'a' tags with class 'gamePod-link'\n",
    "        game_links = soup.find_all('a', class_='gamePod-link')\n",
    "\n",
    "        # Extract the href attribute from each 'a' tag\n",
    "        hrefs = [link['href'] for link in game_links]\n",
    "        game_ids = [href.split('/')[2] for href in hrefs]\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        \n",
    "    return game_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f35930-1249-4c5a-9c49-2be349f1258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    home_id = str(data['meta']['teams'][0]['id'])  # Convert to string\n",
    "    away_id = str(data['meta']['teams'][1]['id'])  # Convert to string\n",
    "    home_name = data['meta']['teams'][0]['shortName']\n",
    "    away_name = data['meta']['teams'][1]['shortName']\n",
    "\n",
    "    players_list = []\n",
    "\n",
    "    for team in data['teams']:\n",
    "        team_id = str(team['teamId'])  # Convert to string for comparison\n",
    "        \n",
    "        if team_id == home_id:\n",
    "            team_type = 'Home'\n",
    "            team_name = home_name\n",
    "        elif team_id == away_id:\n",
    "            team_type = 'Away'\n",
    "            team_name = away_name\n",
    "        else:\n",
    "            print(f\"Unexpected Team ID: {team_id}\")\n",
    "            continue\n",
    "\n",
    "        for player in team['playerStats']:\n",
    "            full_name = f\"{player['firstName']} {player['lastName']}\"\n",
    "            full_name = clean_name(full_name)\n",
    "\n",
    "            # Ensure numeric values are properly cast to integers (or floats if needed)\n",
    "            position = player['position']\n",
    "            minutes_played = int(player['minutesPlayed'])\n",
    "            goals = int(player['goals'])\n",
    "            assists = int(player['assists'])\n",
    "            shots = int(player['shots'])\n",
    "            shots_on_target = int(player['shotsOnGoal'])\n",
    "            yellow_cards = player['yellowCards']\n",
    "            red_cards = player['redCards']\n",
    "\n",
    "            players_list.append({\n",
    "                'Name': full_name,\n",
    "                'Position': position,\n",
    "                'Minutes Played': minutes_played,\n",
    "                'Goals': goals,\n",
    "                'Assists': assists,\n",
    "                'Shots': shots,\n",
    "                'Shots On Target': shots_on_target,\n",
    "                'Team': team_name\n",
    "            })\n",
    "            \n",
    "    return players_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e6a46e-4a32-49fe-bbc9-96b8d7938c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_whole_minutes(time_str):\n",
    "    minutes, _ = map(int, time_str.split(':'))  # Ignore seconds, only take minutes\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fa7813-1d1d-41ff-b18f-20ccfac5b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(game_ids):\n",
    "    players_data = []\n",
    "\n",
    "    for game_id in game_ids:\n",
    "        data = None  # Initialize data variable\n",
    "\n",
    "        try:\n",
    "            # Attempt to make a GET request using the requests library\n",
    "            response = requests.get(f'https://data.ncaa.com/casablanca/game/{game_id}/boxscore.json')\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            data = response.json()  # Parse the JSON data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data via requests for game ID {game_id}: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Fallback to using curl with os.popen\n",
    "                result = os.popen(\n",
    "                    f'curl https://data.ncaa.com/casablanca/game/{game_id}/boxscore.json'\n",
    "                ).read()\n",
    "                data = json.loads(result)  # Parse the JSON data\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for game ID {game_id} using curl: {e}\")\n",
    "                continue  # Skip to the next game ID\n",
    "\n",
    "        # Check if 'meta' key exists in the data\n",
    "        if data is None or 'meta' not in data:\n",
    "            print(f\"Error: 'meta' key not found in data for game ID {game_id}\")\n",
    "            continue\n",
    "\n",
    "        # Extract team information\n",
    "        home_team = None\n",
    "        away_team = None\n",
    "        for team in data['meta']['teams']:\n",
    "            if team['homeTeam'] == 'true':\n",
    "                home_team = team['shortName']\n",
    "            else:\n",
    "                away_team = team['shortName']\n",
    "\n",
    "        # Clean the data (assumed to be defined elsewhere)\n",
    "        cleaned_data = clean_data(data)\n",
    "\n",
    "        # Append cleaned data to players_data\n",
    "        players_data.append(cleaned_data)\n",
    "\n",
    "    return players_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d218800b-12f9-4d18-8684-b51761f25703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_event(event):\n",
    "    if 'Goal by' in event:\n",
    "        return 'Goal'\n",
    "    elif 'Shot by' in event:\n",
    "        return 'Shot'\n",
    "    elif 'Foul on' in event:\n",
    "        return 'Foul'\n",
    "    elif 'Corner kick' in event:\n",
    "        return 'Corner Kick'\n",
    "    elif 'Offside' in event:\n",
    "        return 'Offside'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ac821d-9fe4-4d7e-9aeb-a7e4e4129d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player(event):\n",
    "    # Patterns to capture both \"Lastname, Firstname\" and \"Firstname Lastname\"\n",
    "    pattern = r'\\b[A-Z][a-z]+,?\\s*[A-Z][a-z]+'\n",
    "    matches = re.findall(pattern, event)\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb4639d-676c-45c6-9ab8-7a4b6e96b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fouls_won(game_ids):\n",
    "    foul_data = []\n",
    "    for game_id in game_ids:\n",
    "        data = None  # Initialize data variable\n",
    "\n",
    "        try:\n",
    "            # Attempt to make a GET request using the requests library\n",
    "            response = requests.get(f'https://data.ncaa.com/casablanca/game/{game_id}/pbp.json')\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            data = response.json()  # Parse the JSON data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data via requests for game ID {game_id}: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Fallback to using curl with os.popen\n",
    "                result = os.popen(\n",
    "                    f'curl https://data.ncaa.com/casablanca/game/{game_id}/pbp.json'\n",
    "                ).read()\n",
    "                data = json.loads(result)  # Parse the JSON data\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for game ID {game_id} using curl: {e}\")\n",
    "                continue  # Skip to the next game ID\n",
    "\n",
    "        # Validate the JSON structure\n",
    "        if not data or 'meta' not in data or 'periods' not in data:\n",
    "            print(f\"Invalid data for game ID {game_id}\")\n",
    "            continue\n",
    "\n",
    "        # Extract team names\n",
    "        home = data['meta']['teams'][0]['shortName']\n",
    "        away = data['meta']['teams'][1]['shortName']\n",
    "\n",
    "        events = []\n",
    "        score = '0-0'  # Initialize the score\n",
    "        for period in data['periods']:\n",
    "            for play in period['playStats']:\n",
    "                score = play['score'] if play['score'] else score\n",
    "                time = play['time']\n",
    "\n",
    "                if play['visitorText']:\n",
    "                    team = 1\n",
    "                    event = play['visitorText']\n",
    "                else:\n",
    "                    team = 0\n",
    "                    event = play['homeText']\n",
    "\n",
    "                event_details = {\n",
    "                    'Score': score,\n",
    "                    'Time': time,\n",
    "                    'Event': event,\n",
    "                    'Team': team\n",
    "                }\n",
    "                events.append(event_details)\n",
    "\n",
    "        # Create a DataFrame for events\n",
    "        df = pd.DataFrame(events)\n",
    "\n",
    "        df['Name'] = df['Event'].apply(extract_player)  # Rename Player to Name\n",
    "        df['Name'] = df['Name'].apply(clean_name)\n",
    "        df['Event_Type'] = df['Event'].apply(categorize_event)\n",
    "        df['Team'] = df['Team'].apply(lambda x: home if x == 0 else away)\n",
    "        df['IsFoul'] = df['Event'].str.contains('Foul', case=False)\n",
    "\n",
    "        # Filter fouls and summarize\n",
    "        foul_df = df[df['IsFoul']]\n",
    "        foul_summary = foul_df.groupby(['Name', 'Team']).size().reset_index(name='Fouls')\n",
    "        # Append the foul summary for the game\n",
    "        foul_data.append(foul_summary)\n",
    "\n",
    "    # Combine all games' foul summaries into a single DataFrame\n",
    "    if foul_data:\n",
    "        all_fouls = pd.concat(foul_data, ignore_index=True)\n",
    "        return all_fouls\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['Name', 'Team', 'Fouls'])  # Return an empty DataFrame if no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f68e9e7-7df8-41bf-8970-a7ac5c8ade92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def clean_name(name):\n",
    "    if not name:\n",
    "        return \"\"\n",
    "    if ', ' in name:\n",
    "        name = ' '.join(name.split(', ')[::-1])  # Reverse names if in \"Last, First\" format\n",
    "    name = unidecode(name)  # Remove accents and special characters\n",
    "    name = name.strip().title()  # Strip extra spaces and standardize capitalization\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5e98f0-125c-4426-9169-9631d8fee3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Preprocess names to simplify matching\n",
    "def preprocess_name(name):\n",
    "    if not name:\n",
    "        return \"\"\n",
    "    # Remove accents, extra spaces, and lowercase\n",
    "    name = unidecode(name).strip().lower()\n",
    "    return name\n",
    "\n",
    "# Enhanced standardize_names function\n",
    "def standardize_names(names, similarity_threshold=85):\n",
    "    standardized_names = {}\n",
    "    processed_names = [preprocess_name(name) for name in names]\n",
    "    unique_processed_names = list(set(processed_names))\n",
    "\n",
    "    for name in unique_processed_names:\n",
    "        # Fuzzy match against already standardized names\n",
    "        match = process.extractOne(name, list(standardized_names.keys()), scorer=fuzz.token_set_ratio)\n",
    "        if match and match[1] > similarity_threshold:\n",
    "            standardized_names[name] = standardized_names[match[0]]\n",
    "        else:\n",
    "            standardized_names[name] = name\n",
    "\n",
    "    return [standardized_names[preprocess_name(name)] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed9535f-86a2-4c7e-a5a4-54f968826f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_name_mapping(*name_lists, similarity_threshold=90):\n",
    "    all_names = set()\n",
    "    for names in name_lists:\n",
    "        all_names.update(preprocess_name(name) for name in names)\n",
    "    \n",
    "    standardized_names = {}\n",
    "    unique_processed_names = list(all_names)\n",
    "\n",
    "    for name in unique_processed_names:\n",
    "        # Match with already standardized names\n",
    "        match = process.extractOne(name, standardized_names.keys(), scorer=fuzz.WRatio)\n",
    "        if match and match[1] > similarity_threshold:\n",
    "            standardized_names[name] = standardized_names[match[0]]\n",
    "        else:\n",
    "            standardized_names[name] = name\n",
    "\n",
    "    return standardized_names\n",
    "\n",
    "# Apply the global mapping\n",
    "def apply_name_mapping(names, name_mapping):\n",
    "    return [name_mapping[preprocess_name(name)] for name in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa1414f-e974-435b-8562-9bb66df5b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2024-08-22'\n",
    "end_date = '2024-12-16'\n",
    "# Generate a date range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Extract month/day for each date\n",
    "time_range = date_range.strftime('%m/%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8a673a-dcd1-4682-9382-55a9360a46a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/22\n",
      "[]\n",
      "08/22 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/23\n",
      "[]\n",
      "08/23 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/24\n",
      "[]\n",
      "08/24 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/25\n",
      "[]\n",
      "08/25 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/26\n",
      "[]\n",
      "08/26 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/27\n",
      "[]\n",
      "08/27 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/28\n",
      "[]\n",
      "08/28 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/29\n",
      "[]\n",
      "08/29 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/30\n",
      "[]\n",
      "08/30 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/08/31\n",
      "[]\n",
      "08/31 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/09/01\n",
      "[]\n",
      "09/01 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/09/02\n",
      "[]\n",
      "09/02 Done!\n",
      "https://www.ncaa.com/scoreboard/soccer-men/d1/2024/09/03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Iterate over the date range to collect game data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day \u001b[38;5;129;01min\u001b[39;00m time_range:\n\u001b[1;32m----> 8\u001b[0m     game_ids \u001b[38;5;241m=\u001b[39m get_game_ids(day, division)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(game_ids)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Collect player data and fouls\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m, in \u001b[0;36mget_game_ids\u001b[1;34m(day, division)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Send a request to fetch the HTML content of the page\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Parse the HTML content using BeautifulSoup\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists for storing data\n",
    "dfs = []\n",
    "fouls = []\n",
    "division = 'd1'\n",
    "\n",
    "# Iterate over the date range to collect game data\n",
    "for day in time_range:\n",
    "    game_ids = get_game_ids(day, division)\n",
    "    # Collect player data and fouls\n",
    "    players_data = collect_data(game_ids)\n",
    "    fouls_won = collect_fouls_won(game_ids)\n",
    "\n",
    "    # Flatten nested list of player data into a single list\n",
    "    flattened_data = [player for game in players_data for player in game]\n",
    "    \n",
    "    # Create DataFrames for player data and fouls\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "    fouls.append(fouls_won)\n",
    "    dfs.append(df)\n",
    "    print(day, \"Done!\")\n",
    "\n",
    "# Concatenate all the collected data\n",
    "dfs = pd.concat(dfs, ignore_index=True)\n",
    "fouls = pd.concat(fouls, ignore_index=True)\n",
    "\n",
    "# Clean and standardize names\n",
    "dfs['Name'] = dfs['Name'].apply(clean_name)\n",
    "fouls['Name'] = fouls['Name'].apply(clean_name)\n",
    "\n",
    "# Collect all names for mapping\n",
    "all_names = list(dfs['Name']) + list(fouls['Name'])\n",
    "name_mapping = create_name_mapping(all_names)\n",
    "\n",
    "# Standardize names using the unified mapping\n",
    "dfs['Name'] = apply_name_mapping(dfs['Name'], name_mapping)\n",
    "fouls['Name'] = apply_name_mapping(fouls['Name'], name_mapping)\n",
    "\n",
    "# Group data by Name and Team\n",
    "final_df = dfs.groupby(['Name', 'Team'], as_index=False).sum()\n",
    "fouls = fouls.groupby(['Name', 'Team'], as_index=False).sum()\n",
    "\n",
    "# Filter out invalid names\n",
    "player_stats = final_df[final_df['Name'].notnull() & (final_df['Name'].str.strip() != '')]\n",
    "\n",
    "# Merge fouls into player stats based on Name and Team\n",
    "player_stats = pd.merge(player_stats, fouls, on=['Name', 'Team'], how='left', suffixes=('', '_fouls'))\n",
    "player_stats['Fouls Won'] = player_stats['Fouls']\n",
    "player_stats['Fouls Won'] = player_stats['Fouls Won'].fillna(0)\n",
    "\n",
    "# Prepare the final player stats DataFrame\n",
    "player_stats = player_stats[['Name', 'Team', 'Position', 'Minutes Played', 'Goals', 'Assists', 'Shots', 'Shots On Target', 'Fouls Won']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe803ef-a3b9-4f0c-b600-82f34c3f76b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'player_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m player_stats\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'player_stats' is not defined"
     ]
    }
   ],
   "source": [
    "df = player_stats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eca11e-9c8d-45f1-af79-94ea3823a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c943e-6851-46e8-9133-3307ff3fb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update fouls based on subset matches\n",
    "def update_fouls_for_subset_names(df, fouls):\n",
    "    df = df.copy()\n",
    "    # Iterate through player_stats where Fouls Won is 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['Fouls Won'] == 0:\n",
    "            # Search for names in fouls that are subsets of the player's name\n",
    "            matching_fouls = fouls[\n",
    "                (fouls['Team'] == row['Team']) &\n",
    "                (fouls['Name'].apply(lambda x: row['Name'] in x or x in row['Name']))\n",
    "            ]\n",
    "            if not matching_fouls.empty:\n",
    "                # Sum up fouls won for matching names\n",
    "                total_fouls = matching_fouls['Fouls'].sum()\n",
    "                df.at[idx, 'Fouls Won'] = total_fouls\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "df = update_fouls_for_subset_names(df, fouls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdef3b6-4120-441c-aa9e-1ae7007ddec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate dominant position\n",
    "def dominant_position(pos):\n",
    "    if pd.isna(pos) or not isinstance(pos, str) or len(pos) == 0:\n",
    "        return \"Unknown\"  # Handle empty or invalid inputs\n",
    "    \n",
    "    # Define position mapping and their keywords\n",
    "    position_keywords = {\n",
    "        'Midfielder': ['M', 'Midfielder'],\n",
    "        'Defender': ['D', 'Defender'],\n",
    "        'Forward': ['F', 'Forward'],\n",
    "        'Goalkeeper': ['G', 'Goalkeeper']\n",
    "    }\n",
    "    \n",
    "    # Count occurrences of each position keyword in the string\n",
    "    position_counts = {\n",
    "        position: sum(pos.upper().count(keyword.upper()) for keyword in keywords)\n",
    "        for position, keywords in position_keywords.items()\n",
    "    }\n",
    "    \n",
    "    # Handle cases where no valid position-related keywords exist\n",
    "    if all(count == 0 for count in position_counts.values()):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Get the position with the maximum count\n",
    "    dominant_position = max(position_counts, key=position_counts.get)\n",
    "    return dominant_position\n",
    "\n",
    "# Apply the function to the Position column\n",
    "df['Position'] = df['Position'].apply(dominant_position)\n",
    "df['Name'] = df['Name'].apply(lambda x: x.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d29490-ed27-440a-aaf9-3b01c0b9443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8695bf-712d-4a14-b4a1-a732232df831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('d2_player_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
